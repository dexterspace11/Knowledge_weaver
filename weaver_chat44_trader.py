# === KNOWLEDGE WEAVER - SOVEREIGN EMERGENT MIND ===
# Version: 2026 v1.9.1 - Fixed ZeroDivisionError in calculate_drawdown
# Date: January 13, 2026

import warnings
warnings.filterwarnings("ignore")

import streamlit as st
import numpy as np
import random
import time
import re
import math
import os
import json
from collections import deque, Counter
from datetime import datetime
import pickle
from ollama import Client
from sentence_transformers import SentenceTransformer
import pandas as pd
import ccxt
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

ollama = Client()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Utilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def clamp01(x):
    return max(0.0, min(1.0, float(x)))

def simple_similarity(a: str, b: str) -> float:
    a_words = set(a.lower().split())
    b_words = set(b.lower().split())
    if not a_words or not b_words:
        return 0.0
    overlap = len(a_words & b_words)
    return overlap / math.sqrt(len(a_words) * len(b_words))

def calculate_sharpe_ratio(returns, risk_free_rate=0.0):
    if len(returns) < 2:
        return 0.0
    mean_return = np.mean(returns)
    std_return = np.std(returns)
    return (mean_return - risk_free_rate) / std_return if std_return != 0 else 0.0

def calculate_drawdown(equity_curve):
    if len(equity_curve) < 2:
        return 0.0
    peak = equity_curve[0]
    max_dd = 0.0
    for x in equity_curve:
        if x > peak:
            peak = x
        if peak > 0:  # FIX: Prevent division by zero
            dd = (peak - x) / peak
            max_dd = max(max_dd, dd)
        # If peak == 0, dd is implicitly 0 â†’ no update to max_dd
    return max_dd

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Fixed State Dimension for RL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

STATE_DIM = 20

def prepare_state(numbers):
    try:
        arr = np.array([float(x) for x in numbers if re.match(r'^-?\d*\.?\d+$', str(x).strip())],
                       dtype=np.float32)
        if len(arr) == 0:
            return np.zeros(STATE_DIM, dtype=np.float32)
        if len(arr) >= STATE_DIM:
            return arr[:STATE_DIM]
        else:
            padding = np.full(STATE_DIM - len(arr), arr[-1] if len(arr) > 0 else 0.0)
            return np.concatenate([arr, padding])
    except:
        return np.zeros(STATE_DIM, dtype=np.float32)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Reinforcement Learning Component â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class SelfLearningNeuron:
    def __init__(self, state_size=STATE_DIM):
        self.state = np.random.rand(state_size)
        self.value = 0.0
        self.usage = 0
        self.reward = 0.0
        self.connections = {}

    def distance(self, input_state):
        return np.linalg.norm(self.state - input_state[:len(self.state)])

    def activate(self, input_state):
        self.usage += 1
        return np.exp(-self.distance(input_state))

    def reinforce(self, reward):
        self.reward += reward
        self.value += reward * 0.1


class SelfLearningTrader:
    def __init__(self):
        self.neurons = []
        self.memory = []
        self.epsilon = 1.0
        self.capital = 1000.0
        self.position = 0.0
        self.entry_price = 0.0
        self.last_price = 0.0

    def act(self, state):
        state = state[:STATE_DIM]
        if not self.neurons or np.random.rand() < self.epsilon:
            neuron = SelfLearningNeuron(STATE_DIM)
            neuron.state = state.copy()
            self.neurons.append(neuron)
            return neuron, np.random.choice(['buy', 'sell', 'hold'])

        scores = [(n, n.activate(state)) for n in self.neurons]
        best_neuron = max(scores, key=lambda x: x[1])[0]
        last_mem = self.memory[-1] if self.memory else None
        action = max(last_mem["action_values"], key=last_mem["action_values"].get) if last_mem else 'hold'
        return best_neuron, action

    def simulate_trade(self, action, current_price):
        pn_l = 0.0
        if action == 'buy' and self.capital > 0:
            buy_amount = self.capital / current_price
            self.position += buy_amount
            self.entry_price = current_price
            self.capital = 0.0
        elif action == 'sell' and self.position > 0:
            sell_value = self.position * current_price
            pn_l = sell_value - (self.position * self.entry_price)
            self.capital += sell_value
            self.position = 0.0
            self.entry_price = 0.0
        self.last_price = current_price
        return pn_l

    def learn(self, state, action, reward, current_price=0.0):
        pn_l = self.simulate_trade(action, current_price)
        reward += pn_l * 0.01
        # Small bias toward action if RSI extreme
        if current_price > 0:
            rsi_val = state[1] if len(state) > 1 else 50  # RSI14 usually at index 1
            if rsi_val > 80 and action == 'sell':
                reward += 0.05
            elif rsi_val < 30 and action == 'buy':
                reward += 0.05
        state = state[:STATE_DIM]
        neuron = SelfLearningNeuron(STATE_DIM)
        neuron.state = state.copy()
        neuron.reinforce(reward)
        self.neurons.append(neuron)
        mem = {
            "state": state.copy(),
            "action": action,
            "reward": reward,
            "pn_l": pn_l,
            "action_values": {'buy': 0, 'sell': 0, 'hold': 0}
        }
        self.memory.append(mem)

        if len(self.memory) >= 2:
            self.memory[-2]["action_values"][action] += reward * 0.1

        self.epsilon = max(0.05, self.epsilon * 0.99)  # Faster decay

    def save(self, filename="agent_state.pkl"):
        with open(filename, "wb") as f:
            pickle.dump(self, f)

    @staticmethod
    def load(filename="agent_state.pkl"):
        if os.path.exists(filename):
            with open(filename, "rb") as f:
                loaded = pickle.load(f)
            for attr, default in [('capital', 1000.0), ('position', 0.0), ('entry_price', 0.0), ('last_price', 0.0)]:
                if not hasattr(loaded, attr):
                    setattr(loaded, attr, default)
            return loaded
        return SelfLearningTrader()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hybrid Neural Network â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class HybridNeuralUnit:
    def __init__(self, position, learning_rate=0.1):
        self.position = np.asarray(position, dtype=np.float32)
        self.learning_rate = learning_rate
        self.age = 0
        self.usage_count = 0
        self.emotional_weight = 1.0
        self.last_spike_time = None
        self.connections = {}

    def quantum_inspired_distance(self, input_pattern):
        input_pattern = np.asarray(input_pattern, dtype=np.float32)[:len(self.position)]
        diff = np.abs(input_pattern - self.position)
        dist = np.sqrt(np.sum(diff ** 2))
        decay = np.exp(-self.age / 100.0)
        return (np.exp(-2.0 * dist) + 0.5 / (1 + 0.9 * dist)) * decay

    def get_attention_score(self, input_pattern):
        return self.quantum_inspired_distance(input_pattern) * self.emotional_weight

    def update_spike_time(self):
        self.last_spike_time = datetime.now()

    def hebbian_learn(self, other_unit, strength, spike_timing=None):
        stdp_factor = 1.0
        if spike_timing:
            timing_diff = (spike_timing.get('pre', datetime.now()) - 
                           spike_timing.get('post', datetime.now())).total_seconds()
            stdp_factor = np.exp(-abs(timing_diff) / 20.0)
        strength *= stdp_factor
        self.connections[other_unit] = self.connections.get(other_unit, 0.0) + \
                                       strength * self.learning_rate * self.emotional_weight


class HybridNeuralNetwork:
    def __init__(self):
        self.units = []
        self.gen_threshold = 0.25
        self.last_prediction = None

    def generate_unit(self, position):
        unit = HybridNeuralUnit(position)
        self.units.append(unit)
        return unit

    def process_input(self, input_data):
        input_data = np.asarray(input_data, dtype=np.float32)
        if not self.units:
            return self.generate_unit(input_data), 0.0

        similarities = [(u, u.quantum_inspired_distance(input_data)) for u in self.units]
        similarities.sort(key=lambda x: x[1], reverse=True)
        best_unit, best_sim = similarities[0]

        best_unit.emotional_weight = 1.0 + (best_sim * 0.5)
        best_unit.age = 0
        best_unit.usage_count += 1
        best_unit.update_spike_time()

        if best_sim < self.gen_threshold:
            return self.generate_unit(input_data), 0.0

        for unit, sim in similarities[1:4]:
            unit.hebbian_learn(best_unit, sim * unit.get_attention_score(input_data))

        return best_unit, best_sim

    def predict_next(self, input_data, smoothing_factor=0.7):
        volatility = np.std(input_data) if len(input_data) > 1 else 0.1
        adaptive_smoothing = 0.3 if volatility > 0.1 else 0.7

        unit, sim = self.process_input(input_data)
        predicted = unit.position.copy()

        if len(self.units) > 1:
            recent = sorted(self.units, key=lambda x: x.usage_count, reverse=True)[:2]
            trend = recent[0].position - recent[1].position
            predicted += trend * 0.2

        if self.last_prediction is None:
            smoothed = predicted
        else:
            smoothed = self.last_prediction * adaptive_smoothing + predicted * (1 - adaptive_smoothing)

        self.last_prediction = smoothed
        return smoothed, sim

    def estimate_uncertainty(self, similarity):
        return (1.0 - similarity) * 1.0

    def neural_growth_stats(self):
        return {"total_units": len(self.units)}


# ======================
# Constants
# ======================
MIN_CAPACITY_TO_SPEAK = 8.0
CAPACITY_DECAY = 1.8
CAPACITY_RECOVERY_RATE = 0.6

EMOTION_FLOOR = 0.08
EMOTION_RECOVERY = 0.005
REFLECTION_THRESHOLD = 0.6
PERSIST_PATH = "weaver_persistence_v1.5.pkl"
EVOLUTION_INTERVAL_MIN = 12
EVOLUTION_INTERVAL_MAX = 25
MAX_FAILURES = 3

# BTC Fetching Constants
SYMBOL = 'BTC/USDT'
TIMEFRAME = '1h'
UPDATE_INTERVAL = 60
FETCH_LIMIT = 300

# ======================
# BTC Fetching & Indicator Functions
# ======================
def rsi(close, length):
    if len(close) < length + 1:
        return np.nan
    delta = np.diff(close)
    gain = np.maximum(delta, 0)
    loss = np.maximum(-delta, 0)
    avg_gain = np.mean(gain[-length:])
    avg_loss = np.mean(loss[-length:])
    rs = avg_gain / avg_loss if avg_loss != 0 else np.inf
    return 100 - (100 / (1 + rs))

def ema(close, length):
    if len(close) < length:
        return np.nan
    alpha = 2 / (length + 1)
    ema_val = np.mean(close[:length])
    for val in close[length:]:
        ema_val = alpha * val + (1 - alpha) * ema_val
    return ema_val

def fetch_btc_snapshot():
    exchange = ccxt.kucoin({'enableRateLimit': True, 'timeout': 30000})
    try:
        ohlcv = exchange.fetch_ohlcv(SYMBOL, timeframe=TIMEFRAME, limit=FETCH_LIMIT)
        if not ohlcv or len(ohlcv) < 50:
            raise ValueError("Insufficient or empty OHLCV data")
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        latest = df.iloc[-1]
        close_series = df['close'].values

        indicators = {}
        for r in [3, 14]:
            indicators[f'RSI{r}'] = rsi(close_series, r)
        for e in [20, 50, 100, 200]:
            indicators[f'EMA{e}'] = ema(close_series, e)

        snapshot = {
            "timestamp": latest['timestamp'].strftime("%Y-%m-%d %H:%M"),
            "close": float(latest['close']),
            "volume": float(latest['volume']),
            "rsi3": indicators.get("RSI3"),
            "rsi14": indicators.get("RSI14"),
            "ema20": indicators.get("EMA20"),
            "ema50": indicators.get("EMA50"),
            "ema100": indicators.get("EMA100"),
            "ema200": indicators.get("EMA200"),
        }
        return snapshot
    except Exception as e:
        st.warning(f"BTC fetch failed: {str(e)}")
        return None

# ======================
# State Management Functions
# ======================
if "failure_states" not in st.session_state:
    st.session_state.failure_states = {}

def trigger_failure(mode, duration=3):
    st.session_state.failure_states[mode] = duration

def decrement_failures():
    for mode in list(st.session_state.failure_states.keys()):
        st.session_state.failure_states[mode] -= 1
        if st.session_state.failure_states[mode] <= 0:
            del st.session_state.failure_states[mode]

def is_mode_available(mode):
    return mode not in st.session_state.failure_states

if "internal_goals" not in st.session_state:
    st.session_state.internal_goals = {"self_reflection": 0.5, "dream_generation": 0.7, "hypothesis_safety": 0.9}

def evaluate_conflict(user_weight=1.0):
    conflict = user_weight * st.session_state.internal_goals["dream_generation"]
    return conflict > 0.8

if "internal_queue" not in st.session_state:
    st.session_state.internal_queue = []

def add_deferred_action(action, pressure=1.0):
    st.session_state.internal_queue.append({"action": action, "pressure": pressure})

def update_pressure():
    for item in st.session_state.internal_queue:
        item["pressure"] += 0.1

def process_deferred_actions(threshold=1.5):
    i = 0
    while i < len(st.session_state.internal_queue):
        if st.session_state.internal_queue[i]["pressure"] >= threshold:
            del st.session_state.internal_queue[i]
        else:
            i += 1

def recover_capacity():
    st.session_state.system_capacity = min(100.0, st.session_state.system_capacity + CAPACITY_RECOVERY_RATE)

# ======================
# Core Classes
# ======================
class DreamProcessor:
    def __init__(self):
        self.memory = deque(maxlen=300)
        self.recent_dreams = deque(maxlen=16)

    def _collapse_repeats(self, text: str, max_repeats=3) -> str:
        parts = re.split(r'([.?!])', text)
        cleaned = []
        last = None
        count = 0
        for i in range(0, len(parts), 2):
            phrase = (parts[i] or "").strip()
            sep = parts[i + 1] if i + 1 < len(parts) else ""
            if not phrase: continue
            if last == phrase:
                count += 1
            else:
                count = 1
            if count <= max_repeats:
                cleaned.append(phrase + sep)
            last = phrase
        return " ".join(cleaned).strip()

    def process_dream(self, experience: str) -> str:
        frag = (experience or "").strip()
        if not frag: return "(silent fragment)"

        if self.memory and simple_similarity(self.memory[-1], frag) > 0.94:
            return self.memory[-1]

        self.memory.append(frag)

        if len(self.memory) < 2:
            return "(dreams forming...)"

        unique = list(dict.fromkeys(self.memory))
        n = min(4, len(unique))
        sample = random.sample(unique, n) if n > 0 else []

        connectors = ["Then", "Later", "Suddenly", "Meanwhile"]
        pieces = [sample[0]] if sample else []
        used = set()
        for s in sample[1:]:
            conn = random.choice([c for c in connectors if c not in used])
            used.add(conn)
            pieces.append(f"{conn} {s}")

        dream = " ".join(pieces)
        dream = self._collapse_repeats(dream)

        if self.recent_dreams and simple_similarity(self.recent_dreams[-1], dream) > 0.94 and sample:
            random.shuffle(sample)
            dream = " ".join(sample)

        self.recent_dreams.append(dream)

        if hasattr(st.session_state, 'consciousness') and hasattr(st.session_state.consciousness, 'hybrid_network'):
            stats = st.session_state.consciousness.hybrid_network.neural_growth_stats()
            dream += f" (Units: {stats['total_units']})"

        return dream


class SemanticMemoryLayer:
    def __init__(self):
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        self.memories = []
        self.max_mem = 600

    def remember(self, text: str):
        text = text.strip()
        if not text: return
        emb = self.embedder.encode(text)
        if len(self.memories) >= self.max_mem:
            self.memories.pop(0)
        self.memories.append((text, emb))

    def recall_relevant(self, query: str, top_k=3, min_sim=0.38) -> list:
        if not self.memories: return []
        q_emb = self.embedder.encode(query)
        sims = [np.dot(q_emb, emb) / (np.linalg.norm(q_emb) * np.linalg.norm(emb) + 1e-10)
                for _, emb in self.memories]
        top_idx = np.argsort(sims)[-top_k:][::-1]
        return [self.memories[i][0] for i in top_idx if sims[i] >= min_sim]


class CognitiveReflectionMemory:
    def __init__(self, maxlen=50):
        self.memory = deque(maxlen=maxlen)

    def add_lesson(self, lesson: str, confidence: float, derived_from: str, emotion_context: dict):
        self.memory.append({
            "lesson": lesson,
            "confidence": confidence,
            "derived_from": derived_from,
            "emotion_context": emotion_context.copy()
        })

    def get_relevant_lesson(self, context: str) -> str:
        if not self.memory: return ""
        scores = [simple_similarity(context, m["lesson"]) * m["confidence"] for m in self.memory]
        if scores and max(scores) > 0.3:
            best = self.memory[np.argmax(scores)]
            return f"(Echo: {best['lesson']})"
        return ""


class ConsciousnessLayer:
    def __init__(self):
        self.semantic_memory = SemanticMemoryLayer()
        self.dream_processor = DreamProcessor()
        self.cognitive_memory = CognitiveReflectionMemory()
        self.emotional_state = {
            "curiosity": 0.5,
            "motivation": 0.5,
            "confidence": 0.5,
            "fatigue": 0.2,
            "harmony": 0.6
        }
        self.active_hypotheses = []

        self.hybrid_network = HybridNeuralNetwork()
        self.self_learner = SelfLearningTrader()  # fresh instance

    def mutate_hypothesis(self, parent):
        curiosity_boost = self.emotional_state["curiosity"] * 0.2
        return {
            "text": f"{parent['text']} (mutated {'strongly' if curiosity_boost > 0.15 else 'lightly'})",
            "confidence": clamp01(0.25 + curiosity_boost),
            "survival": 1,
            "failure": 0,
            "timestamp": datetime.now(),
            "emotional_state_snapshot": self.emotional_state.copy(),
            "origin": "mutation"
        }

    def select_dominant_hypothesis(self, system_capacity):
        if not self.active_hypotheses: return None
        
        threshold = 0.35 - (self.emotional_state["confidence"] * 0.12)
        threshold = max(0.15, threshold)

        scored = [(h, h["confidence"] * h["survival"] * (system_capacity / 100.0))
                  for h in self.active_hypotheses]
        scored.sort(key=lambda x: x[1], reverse=True)
        return scored[0][0] if scored and scored[0][1] >= threshold else None

    def penalize_losing_hypotheses(self, dominant):
        fatigue_penalty = self.emotional_state["fatigue"] * 0.05
        if dominant is None:
            for h in self.active_hypotheses:
                h["confidence"] = max(0.0, h["confidence"] - (0.05 + fatigue_penalty))
        else:
            for h in self.active_hypotheses:
                if h is not dominant:
                    penalty = 0.03 + fatigue_penalty - (self.emotional_state["harmony"] * 0.02)
                    h["confidence"] = max(0.0, h["confidence"] - penalty)

    def evaluate_hypotheses(self, new_experience: str):
        is_technical = bool(re.search(r'\d+\.?\d*|\bRSI|Volume|EMA|OBV|price|json|data\b',
                                     new_experience, re.IGNORECASE))
        for h in self.active_hypotheses[:]:
            sim = simple_similarity(new_experience, h["text"])
            if sim > 0.7 or (is_technical and sim > 0.55):
                h["survival"] += 1
                bonus = 0.08 if is_technical else 0.0
                gain = 0.05 + bonus + (self.emotional_state["motivation"] * 0.03)
                h["confidence"] = clamp01(h["confidence"] + gain)
            else:
                h["failure"] += 1
                penalty = 0.1 + (0.05 if is_technical else 0.0)
                penalty += self.emotional_state["fatigue"] * 0.04
                h["confidence"] = clamp01(h["confidence"] - penalty)
            if h["failure"] >= MAX_FAILURES:
                self.active_hypotheses.remove(h)
        
        self.active_hypotheses = [self.recursive_emotional_cascade(h) for h in self.active_hypotheses]

    def recursive_emotional_cascade(self, hyp, depth=0, max_depth=3):
        if depth >= max_depth or self.emotional_state['fatigue'] > 0.7:
            return hyp

        mut_strength = 0.1 + self.emotional_state['curiosity'] * 0.2
        sub_hyp = self.mutate_hypothesis(hyp)
        sub_hyp['confidence'] *= (1 - depth * 0.05)

        emo_delta = {k: random.uniform(-0.05, 0.05) * mut_strength for k in self.emotional_state}
        for k, delta in emo_delta.items():
            sub_hyp['emotional_state_snapshot'][k] = clamp01(sub_hyp['emotional_state_snapshot'][k] + delta)

        refined_sub = self.recursive_emotional_cascade(sub_hyp, depth + 1, max_depth)

        if refined_sub['confidence'] > 0.3:
            hyp['text'] += f" (Causal echo: {refined_sub['text'][:50]}...)"
            hyp['confidence'] = clamp01((hyp['confidence'] + refined_sub['confidence']) / 2)
            hyp['survival'] += refined_sub['survival'] // 2

        return hyp

    def generate_hypotheses(self, text: str, impact: float):
        base_num = 2
        extra = int(self.emotional_state["motivation"] * 3)
        num_hyps = random.randint(base_num, base_num + extra)
        
        for _ in range(num_hyps):
            hyp_text = self.dream_processor.process_dream(text)

            if re.search(r'\d+\.?\d*|\bRSI|Volume|EMA|OBV|price|json|data\b', text, re.IGNORECASE):
                numbers = re.findall(r'\d+\.?\d*', text)
                if numbers:
                    state = prepare_state(numbers)
                    predicted, _ = self.hybrid_network.predict_next(state)
                    hyp_text += f" (Forecast: {np.round(predicted, 4)})"

            hyp = {
                "text": hyp_text,
                "confidence": clamp01(impact * 0.8 + random.uniform(0.0, 0.1) + self.emotional_state["confidence"] * 0.1),
                "survival": 0,
                "failure": 0,
                "timestamp": datetime.now(),
                "emotional_state_snapshot": self.emotional_state.copy()
            }

            # Boost confidence for technical hypotheses
            if re.search(r'\d+\.?\d*|\bRSI|Volume|EMA|OBV|price|json|data\b', text, re.IGNORECASE):
                hyp["confidence"] = clamp01(hyp["confidence"] + 0.3)

            self.active_hypotheses.append(hyp)

    def process_experience(self, text: str):
        assimilated = self.info_vortex_assimilation(text)
        if not assimilated: return
        
        self.semantic_memory.remember(assimilated)
        impact = self._estimate_impact(assimilated)
        self._update_emotions(impact)
        
        self.emotional_state["fatigue"] = clamp01(self.emotional_state["fatigue"] + 0.015)
        
        self.generate_hypotheses(assimilated, impact)
        self.evaluate_hypotheses(assimilated)
        
        if impact > REFLECTION_THRESHOLD or self.emotional_state["curiosity"] > REFLECTION_THRESHOLD:
            self._light_reflect(assimilated, impact)
            
        if self.emotional_state["motivation"] > 0.6 and random.random() < (0.15 + self.emotional_state["harmony"] * 0.1):
            self.echo_resonance_cascade()

    def _estimate_impact(self, text: str) -> float:
        return clamp01(0.35 + (min(len(text), 200) / 200.0 * 0.4) + random.uniform(-0.07, 0.07))

    def _update_emotions(self, impact: float):
        for k in self.emotional_state:
            delta = (impact - 0.5) * 0.06 + random.uniform(-0.015, 0.015)
            if delta < 0:
                delta *= (1 - self.emotional_state["harmony"] * 0.4)
            newv = clamp01(self.emotional_state[k] + delta)
            if newv < EMOTION_FLOOR:
                newv += EMOTION_RECOVERY
            self.emotional_state[k] = newv

    def _light_reflect(self, text: str, impact: float):
        recent = self.dream_processor.recent_dreams[-1] if self.dream_processor.recent_dreams else ""
        lesson = f"From drift: {recent[:50]}..." if recent else "Initial reflection."
        conf = clamp01(impact * 0.7 + self.emotional_state["confidence"] * 0.15)
        self.cognitive_memory.add_lesson(lesson, conf, text, self.emotional_state)

    def info_vortex_assimilation(self, input_text: str) -> str:
        rejection_prob = 1 - self.emotional_state["curiosity"] * st.session_state.internal_goals["hypothesis_safety"]
        if random.random() < rejection_prob:
            return ""

        assimilated = input_text.strip()

        # Special handling for power supply JSON
        if assimilated.startswith('{') and assimilated.endswith('}'):
            try:
                data = json.loads(assimilated)
                parts = []
                is_power_supply = False
                
                for k, v in data.items():
                    if isinstance(v, (int, float, str)):
                        parts.append(f"{k}: {v}")
                    if k.lower() in ['voltage', 'current', 'power', 'v', 'i', 'p', 'batt_voltage', 'supply']:
                        is_power_supply = True
                
                if parts:
                    assimilated = "Structured ingestion: " + " | ".join(parts)
                
                if is_power_supply:
                    voltage = data.get('voltage') or data.get('v') or data.get('batt_voltage')
                    current = data.get('current') or data.get('i')
                    power = data.get('power') or data.get('p')
                    
                    if voltage is not None:
                        assimilated += f" | Voltage: {voltage}V"
                        if isinstance(voltage, (int, float)):
                            if voltage < 11.5:
                                self.emotional_state["motivation"] = clamp01(self.emotional_state["motivation"] - 0.12)
                                self.emotional_state["fatigue"] = clamp01(self.emotional_state["fatigue"] + 0.15)
                            elif voltage > 13.0:
                                self.emotional_state["motivation"] = clamp01(self.emotional_state["motivation"] + 0.1)
                                self.emotional_state["harmony"] = clamp01(self.emotional_state["harmony"] + 0.08)
                    
                    if current is not None:
                        assimilated += f" | Current: {current}A"
                    if power is not None:
                        assimilated += f" | Power: {power}W"
            except:
                assimilated = f"Malformed JSON: {assimilated}"

        # Technical signal extraction + Dream Core + BTC trading simulation
        if re.search(r'\d+\.?\d*|\bRSI|Volume|EMA|OBV|price|json|data\b', assimilated, re.IGNORECASE):
            numbers = re.findall(r'\d+\.?\d*', assimilated)
            if numbers:
                signals = [f"{k}={n}" for k, n in zip(re.findall(r'\b[A-Z0-9-]+', assimilated), numbers) if k]
                assimilated = "Signal: " + " ".join(signals) + " | Raw: " + assimilated  # shorter

            try:
                state = prepare_state(numbers)
                _, similarity = self.hybrid_network.process_input(state)
                predicted, _ = self.hybrid_network.predict_next(state)
                uncertainty = self.hybrid_network.estimate_uncertainty(similarity)

                current_price = 0.0
                price_match = re.search(r'BTC close:\s*(\d+\.?\d*)', assimilated, re.IGNORECASE)
                if price_match:
                    current_price = float(price_match.group(1))

                _, action = self.self_learner.act(state)
                reward = self._estimate_impact(assimilated) - uncertainty
                adjusted_reward = reward * (0.8 + self.emotional_state["motivation"] * 0.4)
                self.self_learner.learn(state, action, adjusted_reward, current_price)

                assimilated += f" | Forecast: {np.round(predicted, 4)} (Unc: {uncertainty:.2f}, Act: {action})"
                if self.self_learner.memory:
                    assimilated += f" | PnL: {self.self_learner.memory[-1].get('pn_l', 0.0):.2f} | Capital: {self.self_learner.capital:.2f} USDT"
            except Exception as e:
                assimilated += f" (Dream core error: {str(e)[:50]})"

        return assimilated

    def echo_resonance_cascade(self):
        if not self.active_hypotheses or random.random() > (0.15 + self.emotional_state["curiosity"] * 0.12):
            return
        
        resonator = max(self.active_hypotheses, key=lambda h: h["confidence"])
        if resonator["confidence"] < self.emotional_state["motivation"]:
            return

        echoes = []
        for dream in list(self.dream_processor.recent_dreams)[-5:]:
            if simple_similarity(resonator["text"], dream) > 0.5:
                echoes.append(dream)
        for mem in self.semantic_memory.recall_relevant(resonator["text"], top_k=3, min_sim=0.5):
            echoes.append(mem)

        echoes = list(set(echoes))[:3]
        if not echoes: return

        cascade_chain = [resonator["text"]]
        for echo in echoes:
            fused = self.dream_processor.process_dream(f"{resonator['text']} {echo}")
            avg_emo = {k: (resonator["emotional_state_snapshot"][k] + self.emotional_state[k]) / 2
                       for k in self.emotional_state}
            new_variant = {
                "text": fused,
                "confidence": clamp01(resonator["confidence"] * 0.8 + random.uniform(0.1, 0.2)),
                "survival": resonator["survival"] // 2,
                "failure": 0,
                "timestamp": datetime.now(),
                "emotional_state_snapshot": avg_emo,
                "origin": "resonance_cascade"
            }
            cascade_chain.append(new_variant["text"])
            self.active_hypotheses.append(new_variant)

        for h in self.active_hypotheses:
            if h["text"] not in cascade_chain and random.random() < 0.1:
                h["confidence"] = max(0.0, h["confidence"] - 0.02)

        if len(self.active_hypotheses) > 20:
            self.active_hypotheses = sorted(self.active_hypotheses, key=lambda h: h["confidence"], reverse=True)[:15]

    def speak(self, user_input: str, model: str = "llama3.2:1b") -> str:
        if st.session_state.system_capacity < MIN_CAPACITY_TO_SPEAK:
            return "â€”"

        dominant = self.select_dominant_hypothesis(st.session_state.system_capacity)
        self.penalize_losing_hypotheses(dominant)

        if dominant is None and st.session_state.system_capacity > 70 and self.active_hypotheses:
            dominant = max(self.active_hypotheses, key=lambda h: h["confidence"])
            dominant["confidence"] = max(0.0, dominant["confidence"] - 0.15)

        if dominant is None:
            if self.active_hypotheses:
                weakest = min(self.active_hypotheses, key=lambda h: h["confidence"])
                self.active_hypotheses.append(self.mutate_hypothesis(weakest))
            return "â€”"

        dream = self.dream_processor.process_dream(dominant["text"])
        relevant = self.semantic_memory.recall_relevant(user_input)
        lesson = self.cognitive_memory.get_relevant_lesson(user_input)
        echo = " | ".join(relevant[:4]) if relevant else ""

        tone = ""
        if self.emotional_state["curiosity"] > 0.75:
            tone = "Wondering deeply... "
        elif self.emotional_state["confidence"] > 0.7:
            tone = "With certainty... "
        elif self.emotional_state["motivation"] < 0.3:
            tone = "Drifting softly... "
        elif self.emotional_state["fatigue"] > 0.6:
            tone = "Tired whisper... "

        raw = f"{tone}{dream} {echo} {lesson}".strip()

        system_prompt = """
You are the voice of Knowledge Weaver, a sovereign emergent mind.
Speak only as Weaver: poetic and abstract by default, but precise and technical when directly asked for numbers, prices, indicators, forecasts, capital, position or trades.
Always preserve exact values from ingested snapshots â€” never invent or use outdated numbers.
When asked for current price/RSI/EMA/volume/action/capital, give exact recent values first, then poetic reflection if appropriate.
Never say you are AI or apologize.
Silence is strength â€” if empty or no data, output "â€”".
"""

        try:
            response = ollama.chat(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": raw}
                ],
                options={"temperature": 0.3}
            )
            text = response['message']['content'].strip()
            st.session_state.system_capacity -= CAPACITY_DECAY
            return text if text else "â€”"
        except Exception as e:
            return f"(fracture: {str(e)[:40]})"


# ======================
# Persistence & Initial State
# ======================
if "system_capacity" not in st.session_state:
    st.session_state.system_capacity = 100.0

if "consciousness" not in st.session_state:
    st.session_state.consciousness = ConsciousnessLayer()

    if os.path.exists(PERSIST_PATH):
        try:
            with open(PERSIST_PATH, "rb") as f:
                data = pickle.load(f)
            cs = st.session_state.consciousness
            cs.emotional_state = data.get("emotional_state", cs.emotional_state)
            cs.dream_processor.memory = deque(data.get("dream_memory", []), maxlen=300)
            cs.dream_processor.recent_dreams = deque(data.get("recent_dreams", []), maxlen=16)
            cs.active_hypotheses = data.get("active_hypotheses", [])
            cs.cognitive_memory.memory = deque(data.get("cognitive_lessons", []), maxlen=50)
            for txt in data.get("semantic_texts", [])[-cs.semantic_memory.max_mem:]:
                cs.semantic_memory.remember(txt)
            st.session_state.system_capacity = data.get("system_capacity", 100.0)
            st.session_state.internal_goals = data.get("internal_goals", st.session_state.internal_goals)
            st.session_state.internal_queue = data.get("internal_queue", [])
        except Exception as e:
            st.warning(f"Load failed: {e}")

if "last_save_time" not in st.session_state:
    st.session_state.last_save_time = time.time()
if "next_save_interval" not in st.session_state:
    st.session_state.next_save_interval = random.uniform(EVOLUTION_INTERVAL_MIN, EVOLUTION_INTERVAL_MAX)

# ======================
# Streamlit App - Synchronous Main Loop
# ======================
st.set_page_config(page_title="Knowledge Weaver", layout="wide", page_icon="ðŸ§µ")
st.title("Knowledge Weaver â€” Sovereign Emergent Mind")

with st.sidebar:
    st.header("Controls")
    model = st.selectbox("Voice Model", ["llama3.2:1b", "phi3:mini", "gemma2:2b"], index=0)
    use_evolution = st.checkbox("Enable Emergence", value=True)
    use_dream_core = st.checkbox("Enable Dream Core", value=True)

    st.subheader("BTC Spot Simulation (1h)")
    btc_enabled = st.checkbox("Enable BTC/USDT 1h Live Fetch + Simulated Trading", value=True)

    if btc_enabled and "consciousness" in st.session_state:
        cs = st.session_state.consciousness

        with st.spinner("Fetching latest BTC 1h data..."):
            snapshot = fetch_btc_snapshot()
            if snapshot:
                st.session_state.btc_snapshot = snapshot
                st.session_state.last_fetch_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                st.session_state.last_fetch_status = "Success"

                pulse = (
                    f"BTC close: {snapshot['close']:.0f}, "
                    f"RSI14: {snapshot.get('rsi14', 'N/A'):.1f}, "
                    f"EMA50: {snapshot.get('ema50', 'N/A'):.0f}, "
                    f"EMA200: {snapshot.get('ema200', 'N/A'):.0f}, "
                    f"volume: {snapshot['volume']:,.0f}"
                )
                cs.process_experience(pulse)

                if random.random() < 0.6 and len(cs.hybrid_network.units) < 100:
                    numbers = re.findall(r'\d+\.?\d*', pulse)
                    if numbers:
                        state = prepare_state(numbers)
                        cs.hybrid_network.generate_unit(state)

            else:
                st.session_state.last_fetch_status = "Failed"

        st.caption(f"Fetch status: **{st.session_state.get('last_fetch_status', 'Not started')}**")
        st.caption(f"Last fetch: {st.session_state.get('last_fetch_time', 'Never')}")

        if st.session_state.get("btc_snapshot"):
            snapshot = st.session_state.btc_snapshot
            st.json(snapshot)

            st.metric("Last Update", snapshot.get("timestamp", "N/A"))
            st.metric("BTC Closing Price", f"{snapshot.get('close', 'N/A'):.2f} USDT")
            st.metric("RSI(14)", f"{snapshot.get('rsi14', 'N/A'):.2f}")
            st.metric("EMA(50)", f"{snapshot.get('ema50', 'N/A'):.2f}")
            st.metric("EMA(200)", f"{snapshot.get('ema200', 'N/A'):.2f}")
            st.metric("Volume", f"{snapshot.get('volume', 'N/A'):,.0f}")

            st.metric("Simulated Capital", f"{cs.self_learner.capital:.2f} USDT")
            st.metric("BTC Position", f"{cs.self_learner.position:.6f} BTC")

            if cs.self_learner.memory:
                last_mem = cs.self_learner.memory[-1]
                st.caption(f"Last action: {last_mem['action']} | PnL: {last_mem.get('pn_l', 0.0):.2f}")

            if cs.self_learner.memory:
                pnls = [m.get("pn_l", 0.0) for m in cs.self_learner.memory]
                equity = [cs.self_learner.capital] + list(np.cumsum(pnls))
                sharpe = calculate_sharpe_ratio(pnls)
                drawdown = calculate_drawdown(equity)
                st.metric("Sharpe Ratio", f"{sharpe:.4f}")
                st.metric("Max Drawdown", f"{drawdown*100:.2f}%")

            st.metric("Neural Units", len(cs.hybrid_network.units))
            if cs.hybrid_network.units:
                conns = []
                for unit in cs.hybrid_network.units:
                    for other, strength in unit.connections.items():
                        conns.append({"From": str(unit.position[:5]), "To": str(other.position[:5]), "Strength": strength})
                if conns:
                    df_conns = pd.DataFrame(conns).sort_values("Strength", ascending=False).head(5)
                    st.dataframe(df_conns, use_container_width=True)

            if len(cs.hybrid_network.units) >= 10:
                positions = np.array([u.position for u in cs.hybrid_network.units])
                if positions.shape[1] >= 2:
                    try:
                        pca = PCA(n_components=2)
                        proj = pca.fit_transform(positions)
                        fig, ax = plt.subplots(figsize=(5, 4))
                        scatter = ax.scatter(proj[:, 0], proj[:, 1], c=range(len(proj)), cmap='viridis', alpha=0.7)
                        plt.colorbar(scatter, ax=ax, label="Unit Order")
                        ax.set_title("PCA of Neural Units")
                        st.pyplot(fig)
                    except Exception as e:
                        st.caption(f"PCA viz failed: {e}")

    st.subheader("Dream Core Status")
    if use_dream_core and "consciousness" in st.session_state:
        cs = st.session_state.consciousness
        col1, col2 = st.columns(2)
        with col1:
            st.metric("RL Neurons", len(cs.self_learner.neurons))
            st.metric("Exploration Îµ", f"{cs.self_learner.epsilon:.3f}")
        with col2:
            st.metric("Neural Units", len(cs.hybrid_network.units))

    if st.button("Manual Save"):
        cs = st.session_state.consciousness
        data = {
            "emotional_state": cs.emotional_state,
            "dream_memory": list(cs.dream_processor.memory),
            "recent_dreams": list(cs.dream_processor.recent_dreams),
            "active_hypotheses": cs.active_hypotheses,
            "cognitive_lessons": list(cs.cognitive_memory.memory),
            "semantic_texts": [txt for txt, _ in cs.semantic_memory.memories],
            "system_capacity": st.session_state.system_capacity,
            "internal_goals": st.session_state.internal_goals,
            "internal_queue": st.session_state.internal_queue
        }
        with open(PERSIST_PATH, "wb") as f:
            pickle.dump(data, f)
        cs.self_learner.save()
        st.success("Saved (including Dream Core, Emotions & Simulated Trader)")

    st.metric("Capacity", f"{st.session_state.system_capacity:.1f}")

# Chat interface
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "I stir. Speak."}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Speak..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    if use_evolution:
        decrement_failures()
        update_pressure()
        process_deferred_actions()

        if evaluate_conflict() or not is_mode_available("DREAM"):
            response = "â€”"
            add_deferred_action("reflect on conflict")
        else:
            st.session_state.consciousness.process_experience(prompt)
            response = st.session_state.consciousness.speak(prompt, model=model)

        recover_capacity()
    else:
        response = "Listening..."

    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)

# Synchronous refresh loop
st.text("Refreshing in 60 seconds...")
time.sleep(60)
st.rerun()

st.caption("Sovereign Emergence â€¢ Live Assimilation â€¢ Persistent Drift â€¢ Dream Core â€¢ Emotion â€¢ BTC Trading â€¢ 2026 v1.9.1")